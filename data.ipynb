{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969ca3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "import datetime\n",
    "import json \n",
    "import os  \n",
    "import pickle\n",
    "from configparser import ConfigParser\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe55ab9",
   "metadata": {},
   "source": [
    "### General helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f475ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format release date\n",
    "def format_release_date(data):\n",
    "    arr = list()\n",
    "    for i,l in enumerate(data):\n",
    "        if ord(l) == 45:\n",
    "            arr.append(i)\n",
    "    date = int(data[0:arr[0]])\n",
    "    month_name = data[arr[0]+1:arr[1]]\n",
    "    datetime_object = datetime.datetime.strptime(month_name, \"%b\")\n",
    "    month = datetime_object.month\n",
    "    year = int(data[arr[1]+1:arr[1]+5])\n",
    "    date = datetime.datetime(year, month, date)\n",
    "    utc_time = calendar.timegm(date.utctimetuple())\n",
    "    return utc_time \n",
    "\n",
    "# format timestamp\n",
    "def date_only_from_datetime(data):\n",
    "    temp = datetime.datetime.fromtimestamp(data)\n",
    "    date = datetime.datetime(temp.year, temp.month, temp.day) # temp.hour\n",
    "    return date\n",
    "\n",
    "# get mean rating for the user x\n",
    "def get_mean_rating(x, mean_rating):\n",
    "    return float(mean_rating[mean_rating['user_id'] == x]['mean_rating'].to_numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557538c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read config.ini file\n",
    "config = ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "fileinfo = config[\"DATASETS\"]\n",
    "\n",
    "path = fileinfo['ori_path']\n",
    "fm_export_path = fileinfo['fm_path']\n",
    "rf_export_path = fileinfo['rf_path']\n",
    "train_set_filename = fileinfo['train_filename']\n",
    "test_set_filename = fileinfo['test_filename']\n",
    "description_filename = fileinfo['description_filename']\n",
    "\n",
    "# import user, data, item and genre data\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv(path + 'ml-100k/u.user', sep='|', names=u_cols, encoding='latin-1', parse_dates=True, header=None) \n",
    "d_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "data = pd.read_csv(path + 'ml-100k/u.data', sep='\\t', names=d_cols, encoding='latin-1', header=None)\n",
    "genre_cols = pd.read_csv(path + 'ml-100k/u.genre', sep='|', header=None)[0].to_numpy().tolist()\n",
    "m_cols = ['movie_id', 'movie_title', 'release_date', 'video_release_date','imdb_url']\n",
    "m_cols.extend(genre_cols)\n",
    "movies = pd.read_csv(path + 'ml-100k/u.item', sep='|', names=m_cols, usecols=range(24), encoding='latin-1', header=None)\n",
    "\n",
    "# merge user, data and item\n",
    "movie_ratings = pd.merge(movies, data)\n",
    "df = pd.merge(movie_ratings, users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5013ddc2",
   "metadata": {},
   "source": [
    "### Before split - general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6226e8e0",
   "metadata": {},
   "source": [
    "- These are columns that need to be preprocessed for both FM and RF, but are don't need to be split beforehand\n",
    "- Columns: \n",
    "  - release_date\n",
    "  - sex\n",
    "  - zip_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fbe257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping some rows that has no release date \n",
    "df.drop(index = df[df['release_date'].isnull() == True].index, inplace = True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# format release_date to unix timestamp\n",
    "df['release_date'] = df['release_date'].apply(lambda x: format_release_date(x))\n",
    "\n",
    "# convert to binary\n",
    "df['sex'] = (df['sex'] == 'M').astype(int)\n",
    "\n",
    "# take first character only\n",
    "df['zip_code'] = df['zip_code'].str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b53e2ec",
   "metadata": {},
   "source": [
    "### Before split - columns for FM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eef961",
   "metadata": {},
   "source": [
    "- These are columns that need preprocessing specific for FM, but don't have to be split beforehand\n",
    "- Columns:\n",
    "  - age\n",
    "  - timestamp\n",
    "  - release_date\n",
    "- In addition, the one-hot-encoders are fitted here, before splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3178623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format age\n",
    "age_labels = []\n",
    "age_bins = np.arange(0,90,10)\n",
    "for i in range(len(age_bins)-1):\n",
    "    age_labels.append(str(age_bins[i]) + '-' + str(age_bins[i+1]))\n",
    "# convert ages to group of age ranges\n",
    "df['fm_age'] = pd.cut(df['age'], bins = age_bins, labels=age_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836f5c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess timestamp and release date\n",
    "# only use year, month and day from the datetime\n",
    "df['fm_timestamp'] = df['timestamp'].apply(lambda x : date_only_from_datetime(x))\n",
    "df['fm_release_date'] = df['release_date']\n",
    "# df['fm_release_date'] = df['release_date'].apply(lambda x : date_only_from_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ed0df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit one-hot-encoders before train/test split\n",
    "ohe_columns = [\"movie_id\", \"user_id\", \"fm_timestamp\", \"fm_release_date\", \"zip_code\", \"fm_age\", \"occupation\"]\n",
    "ohe_encoders = []\n",
    "for col in ohe_columns:\n",
    "    encoder = OneHotEncoder(dtype=int, sparse=False)\n",
    "    encoder.fit(df[[col]])\n",
    "    ohe_encoders.append(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6707df86",
   "metadata": {},
   "source": [
    "### Before split - columns for RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a939f6",
   "metadata": {},
   "source": [
    "- These are columns that need preprocessing specific for RF, but don't need to be split beforehand\n",
    "- Columns: none at the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa92ca9",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef29d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['rating'], axis = 1), df['rating'], random_state=42)\n",
    "\n",
    "# training and test data is combined to a single dataframe\n",
    "df_train = pd.concat([X_train,pd.DataFrame(y_train)], axis = 1)\n",
    "df_test = pd.concat([X_test,pd.DataFrame(y_test)], axis = 1)\n",
    "\n",
    "del(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57fdb10",
   "metadata": {},
   "source": [
    "### After split - general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838494f2",
   "metadata": {},
   "source": [
    "- These are columns that have to be preprocessed after the split.\n",
    "- Columns:\n",
    "  - mean_rate\n",
    "  - cum_mean_rate\n",
    "  - last_watched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d779fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get last watched movie\n",
    "# def get_last_watched(df):\n",
    "#     df.sort_values(['user_id', 'timestamp'], inplace=True)\n",
    "#     # shift the values in movie_id col down by one\n",
    "#     df['last_watched'] = df['movie_id'].shift(1)\n",
    "#     # then set the first value (first movie watched by the user) to 0\n",
    "#     for index, user in users.iterrows():\n",
    "#         idx = df[df['user_id'] == user['user_id']].index[0]\n",
    "#         df.at[idx, 'last_watched'] = df.at[idx, 'movie_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c1b4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df in [df_train, df_test]:\n",
    "#     get_last_watched(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12ab580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean and cumulative mean\n",
    "# it is only done for training data, since we should not take statistics about rating from test data\n",
    "data_train = df_train[['user_id','movie_id','rating','timestamp']]\n",
    "\n",
    "# calculating cumulative mean rating based on timestamp sorted in ascending order\n",
    "data_train = data_train.sort_values(['user_id', 'timestamp']).reset_index(drop=True)\n",
    "data_train['one'] = 1\n",
    "data_train['cumsum'] = data_train.groupby('user_id')['one'].cumsum()\n",
    "data_train['cum_mean_rate'] = data_train.groupby('user_id')['rating'].cumsum() / data_train['cumsum']\n",
    "\n",
    "# calculating mean rating for each user\n",
    "mean_rating = data_train.groupby('user_id')['rating'].sum() / data_train.groupby('user_id')['one'].sum()\n",
    "mean_rating = mean_rating.reset_index()\n",
    "mean_rating.rename(columns = {0:'mean_rating'}, inplace = True)\n",
    "\n",
    "# getting mean rate for the corresponding user\n",
    "data_train['mean_rate'] = data_train['user_id']\n",
    "data_train[\"mean_rate\"] = data_train['mean_rate'].apply(lambda x: get_mean_rating(x, mean_rating))\n",
    "\n",
    "# merging to the original dataframe\n",
    "df_train = df_train.merge(data_train, how='left', left_on=['timestamp', 'user_id', 'movie_id', 'rating'], right_on=['timestamp', 'user_id', 'movie_id', 'rating'])\n",
    "\n",
    "# during testing we won't have the rating value, so we should use the running mean form training data.\n",
    "df_test['mean_rate'] = df_test['user_id'].apply(lambda x: get_mean_rating(x, mean_rating))\n",
    "df_test['cum_mean_rate'] = df_test['mean_rate']\n",
    "\n",
    "del(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635eb5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF forest data needs to be preprocessed differently. \n",
    "# Therefore need to save copy of dfs first\n",
    "rf_df_train = df_train.copy(deep=True)\n",
    "rf_df_test = df_test.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1af166",
   "metadata": {},
   "source": [
    "### After split - FM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4914834",
   "metadata": {},
   "source": [
    "- These are steps that need to be performed after the split, and specifically for FM\n",
    "- Steps:\n",
    "  - OHE and other encoding\n",
    "  - Getting the feature column lengths (col_len)\n",
    "  - Saving the data\n",
    "- columns used in FM:\n",
    "  - movie_id, user_id, timestamp, release_date, zip_code, age, occupation, genre, sex, rating\n",
    "  - TODO: binary encoding last_watched, maybe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f8ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ohe_columns[-1] = \"last_watched\"\n",
    "# ohe_encoders[-1].feature_names_in_ = [ohe_columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1108d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add mean_rate and cum_mean_rate to encoder\n",
    "# for col in ['mean_rate', 'cum_mean_rate']:\n",
    "#     df_train[col] = df_train[col].apply(lambda rate: int(round(rate, 1)*10))\n",
    "#     df_test[col] = df_test[col].apply(lambda rate: int(round(rate, 1)*10))\n",
    "#     ohe_columns.append(col)\n",
    "#     encoder = OneHotEncoder(categories=[[i for i in range(10,51,1)]], dtype=int, sparse=False)\n",
    "#     encoder.fit(df_train[[col]])\n",
    "#     ohe_encoders.append(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223cdec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the final df and set col_len at the same time\n",
    "def encode_df(df, col_len, ohe_cols, ohe_encoders):\n",
    "    # create empty df with correct shape\n",
    "    df_final = pd.DataFrame(columns = [], index = range(len(df)))\n",
    "    \n",
    "    # columns that need ohe\n",
    "    for index, col in enumerate(ohe_cols):\n",
    "        transform = pd.DataFrame(ohe_encoders[index].transform(df[[col]]), columns=ohe_encoders[index].get_feature_names_out())\n",
    "        df_final = pd.concat([df_final, transform], axis = 1)\n",
    "        col_len[col] = len(transform.columns)\n",
    "\n",
    "    # special case: genre (already ohe in original dataset)\n",
    "    col_len[\"genre\"] = len(genre_cols)\n",
    "    df_final = pd.concat([df_final, df[genre_cols]], axis = 1)\n",
    "\n",
    "    # columns that don't need ohe\n",
    "    non_ohe_columns = [\"sex\", \"cum_mean_rate\", 'mean_rate']\n",
    "    for col in non_ohe_columns:\n",
    "        col_len[col] = 1\n",
    "    df_final = pd.concat([df_final, df[non_ohe_columns]], axis = 1)\n",
    "\n",
    "    # rating column (no need to add to col_len)\n",
    "    df_final = pd.concat([df_final, df[['rating']]], axis = 1)\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdb1e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_len = {}\n",
    "\n",
    "#need to reset otherwise pd.concat will not work properly\n",
    "df_test.reset_index(inplace=True)\n",
    "df_train.reset_index(inplace=True)\n",
    "\n",
    "df_test = encode_df(df_test, col_len, ohe_columns, ohe_encoders)\n",
    "df_train = encode_df(df_train, col_len, ohe_columns, ohe_encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ff3d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the FM data\n",
    "# create parent folder if doesn't exist\n",
    "os.makedirs(fm_export_path, exist_ok=True)\n",
    "\n",
    "# export csv file\n",
    "pickle.dump(df_train, open(fm_export_path + train_set_filename, 'wb'))\n",
    "pickle.dump(df_test, open(fm_export_path + test_set_filename, 'wb'))\n",
    "\n",
    "# saving info about data\n",
    "with open(fm_export_path + description_filename, \"w\") as outfile:\n",
    "    json.dump(col_len, outfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df28a143",
   "metadata": {},
   "source": [
    "### After split - RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28b6e92",
   "metadata": {},
   "source": [
    "- These are steps that need to be performed after the split, and specifically for RF\n",
    "- Steps:\n",
    "  - label encoding\n",
    "  - Saving the data\n",
    "- Columns used in RF:\n",
    "  - movie_id, user_id, timestamp, release_date, zip_code, age, \n",
    "  occupation, sex, rating, last_watched, mean_rate, cum_mean_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8283e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns = ['movie_id', 'user_id', \"timestamp\", \"release_date\", \"zip_code\", \"age\", \n",
    "\"occupation\", \"sex\", \"rating\", \"last_watched\", \"mean_rate\", \"cum_mean_rate\"]\n",
    "final_columns.extend(genre_cols)\n",
    "# droping all unnecessary columns\n",
    "df_train = rf_df_train[final_columns]\n",
    "df_test = rf_df_test[final_columns]\n",
    "\n",
    "del(rf_df_train)\n",
    "del(rf_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26dec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting objects to integers, since scikit learn supports only numerical values\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "label_encoding_columns = ['sex']\n",
    "for col in label_encoding_columns:\n",
    "    df_train[col] = le.fit_transform(df_train[col])\n",
    "    df_test[col] = le.fit_transform(df_test[col])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aaa3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create parent folder if doesn't exist\n",
    "os.makedirs(rf_export_path, exist_ok=True)\n",
    "\n",
    "# Saving the RF data\n",
    "pickle.dump(df_train, open(rf_export_path + train_set_filename, 'wb'))\n",
    "pickle.dump(df_test, open(rf_export_path + test_set_filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccac2023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19766db8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".Rmd",
    "format_name": "rmarkdown",
    "format_version": "1.2",
    "jupytext_version": "1.13.8"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
