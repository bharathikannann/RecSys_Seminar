{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ade50f2e",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "\n",
    "- 3 Embedded methods and 1 wrapper method is implemeted in this notebook\n",
    "- Embedded Methods\n",
    "    - Random Forest\n",
    "    - Extra Tree classifier\n",
    "    - Select from K model\n",
    "    \n",
    "- Wrapper methods\n",
    "    - Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb6845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import time\n",
    "from configparser import ConfigParser\n",
    "import os\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b42c3c9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Read config.ini file\n",
    "config = ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "dataset_info = config[\"DATASETS\"]\n",
    "fm_data_path = dataset_info['fm_path']\n",
    "rf_data_path = dataset_info['rf_path']\n",
    "train_set_filename = dataset_info['train_filename']\n",
    "test_set_filename = dataset_info['test_filename']\n",
    "description_filename = dataset_info['description_filename']\n",
    "\n",
    "model_info = config[\"MODELS\"]\n",
    "model_path = model_info['model_path']\n",
    "fm_filename = model_info['fm_model_filename']\n",
    "rf_filename = model_info['rf_model_filename']\n",
    "\n",
    "fs_info = config[\"FEATURE_SELECTION\"]\n",
    "fs_fm_path = fs_info['fs_fm_path']\n",
    "fs_rf_path = fs_info['fs_rf_path']\n",
    "fs_final_path = fs_info['fs_final_path']\n",
    "\n",
    "path = dataset_info['ori_path']\n",
    "genre_cols = pd.read_csv(path + 'ml-100k/u.genre', sep='|', header=None)[0].to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ba382e",
   "metadata": {},
   "source": [
    "### NOTES:\n",
    "- Final outputs are saved in this format: \n",
    "    \n",
    "```python\n",
    "    x_final_dict = {\n",
    "        \"k\": None,\n",
    "        \"columns\": [], # list type\n",
    "        \"importances\": [], # list type, in percentage, and should be sorted\n",
    "    }\n",
    "```\n",
    "- x - model name\n",
    "- columns length are same as importances length\n",
    "- importances are in descending order, and columns follow accordingly\n",
    "- movie_id and user_id columns are excluded before doing feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707ddebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create parent folder if doesn't exist\n",
    "os.makedirs(fs_rf_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8232b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pickle.load(open(fm_data_path + train_set_filename, 'rb'))\n",
    "test = pickle.load(open(fm_data_path + test_set_filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672dfbf8",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b669985",
   "metadata": {},
   "source": [
    "Cummulative mean rate and mean rate is dropped here. This feature has some problems for generealization. The test data is not properly imputed and this feature gave very worst performance with myfm model. So this feature is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c77c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop((['rating','cum_mean_rate','mean_rate']), axis = 1)\n",
    "y = train['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c82696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for later reference, can be removed after all experiments\n",
    "X_original = X.copy(deep = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb852566",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c9a495",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop((['rating','cum_mean_rate','mean_rate']), axis = 1)\n",
    "y_test = test['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca8c985",
   "metadata": {},
   "source": [
    "---\n",
    "Drop user_id and movie_id for feature selection. This is an important feature for the baseline model and we can't remove this feature if it gets a low score. Feature selection is done only for additional features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c7d909",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(X.filter(regex='movie_id').columns, axis=1, inplace=True)\n",
    "X.drop(X.filter(regex='user_id').columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12384728",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop(X_test.filter(regex='movie_id').columns, axis=1, inplace=True)\n",
    "X_test.drop(X_test.filter(regex='user_id').columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2792318a",
   "metadata": {},
   "source": [
    "---\n",
    "# Feature Importance\n",
    "# Feature importance using Random Forest\n",
    "\n",
    "We train a random forest and then we compute how much each feature is contributing to decrease the mean impurity. The features used at the top of the tree is more imortant than the leaf nodes, as they have high information gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b636c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc4cc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize and fit the model\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "forest.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a87d45",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309e08e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87845b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of column names\n",
    "feature_names = list(X.columns)\n",
    "\n",
    "# extract the feature importance values\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "rf_feature_importances = pd.DataFrame(\n",
    "    {\"feature\": feature_names, \"importance\": forest.feature_importances_}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2768e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_feature_importances.sort_values(\"importance\", ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408161e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final_dict = {\n",
    "    \"k\": None,\n",
    "    \"columns\": rf_feature_importances['feature'].tolist(),\n",
    "    \"importances\": rf_feature_importances['importance'].tolist(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f48d30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fs_final_path + \"random-forest-feature-importance_v3.json\", \"w\") as fp:\n",
    "    json.dump(rf_final_dict, fp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4413bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization is nice to have, but not necessary, might be very large for more number of columns\n",
    "# visualize the importance of each feature\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "# ax.set_ylim([0, 30])\n",
    "rf_feature_importances.plot.bar(x='feature', y='importance', ax=ax, legend=False, stacked = True)\n",
    "ax.set_title(\"Feature importances\")\n",
    "ax.set_ylabel(\"Importance in %\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc982e93",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Feature importance using Extra Tree Cassifier\n",
    "\n",
    "It is same as random forest. Except it does not use bootstrapping and the cut is not optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b463e5f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5fa5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tree = ExtraTreesClassifier()\n",
    "extra_tree.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0fbd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the feature importance values\n",
    "std = np.std([tree.feature_importances_ for tree in extra_tree.estimators_], axis=0)\n",
    "et_feature_importances = pd.DataFrame(\n",
    "    {\"feature\": feature_names, \"importance\": extra_tree.feature_importances_}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04accd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_feature_importances.sort_values(\"importance\", ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ae93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the importance of each feature, might be very large for more number of columns\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "et_feature_importances.plot.bar(x='feature', y='importance', yerr=std, ax=ax, legend=False)\n",
    "ax.set_title(\"Feature importances\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcea0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the info\n",
    "et_final_dict = {\n",
    "    \"k\": None,\n",
    "    \"columns\": et_feature_importances['feature'].tolist(),\n",
    "    \"importances\": et_feature_importances['importance'].tolist(),\n",
    "}\n",
    "\n",
    "with open(fs_final_path + \"extra-tree-classifier-feature-importance.json\", \"w\") as fp:\n",
    "    json.dump(et_final_dict, fp) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d921cf1a",
   "metadata": {},
   "source": [
    "---\n",
    "# Select from K Model\n",
    "\n",
    "It uses a base model inside and the weights of the model gives importance about that feature. If the weight is large then that feature is important and if the weight is close to 0 then it is not important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc717e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c7b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddaa6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0 ,550, 50):\n",
    "    \n",
    "    sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l2'), max_features = i)\n",
    "    sel_.fit(scaled, y)\n",
    "    \n",
    "    selected_feat = X.columns[(sel_.get_support())]\n",
    "    print('total no of features: {}'.format((X.shape[1])))\n",
    "    print('No of selected features: {}'.format(len(selected_feat)))\n",
    "    print('features with coefficients shrank to zero: {}'.format(\n",
    "    np.sum(sel_.estimator_.coef_ == 0)))\n",
    "    \n",
    "    # save the info\n",
    "    et_final_dict = {\n",
    "        \"k\": None,\n",
    "        \"columns\": selected_feat.tolist(),\n",
    "        \"importances\": None,\n",
    "    }\n",
    "\n",
    "    with open(fs_final_path + \"/sfm/\" + \"select_from_model_\" + str(i) + \".json\", \"w\") as fp:\n",
    "        json.dump(et_final_dict, fp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feat = X.columns[(sel_.get_support())]\n",
    "print('total no of features: {}'.format((X.shape[1])))\n",
    "print('No of selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "      np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e6fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the info\n",
    "et_final_dict = {\n",
    "    \"k\": None,\n",
    "    \"columns\": selected_feat.tolist(),\n",
    "    \"importances\": None,\n",
    "}\n",
    "\n",
    "with open(fs_final_path + \"select_from_model_500.json\", \"w\") as fp:\n",
    "    json.dump(et_final_dict, fp) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0046b682",
   "metadata": {},
   "source": [
    "___\n",
    "# Permutation Importance\n",
    "\n",
    "A single featue is randomly shuffled each time and we check how it affects the performance. It it not decreasing then that feature is not contributing for the prediction. This is done for all columns and the columns that are not contributing is eliminated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae0bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "start_time = time.time()\n",
    "result = permutation_importance(\n",
    "    forest, X, y, n_repeats=1\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")\n",
    "\n",
    "forest_importances = pd.Series(result.importances_mean, index=feature_names)\n",
    "forest_importances.sort_values(ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea485e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_importances = pd.Series(result.importances_mean, index=feature_names)\n",
    "forest_importances.sort_values(ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd0c633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the info\n",
    "et_final_dict = {\n",
    "    \"k\": None,\n",
    "    \"columns\": forest_importances.index.tolist(),\n",
    "    \"importances\": forest_importances.values.tolist(),\n",
    "}\n",
    "\n",
    "with open(fs_final_path + \"permutation_importance.json\", \"w\") as fp:\n",
    "    json.dump(et_final_dict, fp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19853644",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "forest_importances.plot.bar(yerr=result.importances_std, ax=ax)\n",
    "ax.set_title(\"Feature importances using permutation on full model\")\n",
    "ax.set_ylabel(\"Mean accuracy decrease\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a9a585",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9271f61",
   "metadata": {},
   "source": [
    "# Mutual Info Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f93303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e89273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info = mutual_info_regression(X, y)\n",
    "mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35742576",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info = pd.Series(mutual_info)\n",
    "mutual_info.index = X.columns\n",
    "mutual_info.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec428ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info.sort_values(ascending=False).plot.bar(figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f07ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info_sort = mutual_info.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2e1fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the info\n",
    "for k in range(50, 550, 50):\n",
    "    mi_final_dict = {\n",
    "        \"k\": k,\n",
    "        \"columns\": mutual_info_sort.index[:k].tolist(),\n",
    "        \"importances\": mutual_info_sort.values[:k].tolist(),\n",
    "    }\n",
    "\n",
    "    with open(fs_fm_path + \"mutual-importance-regression_\" + str(k) + \".json\", \"w\") as fp:\n",
    "        json.dump(mi_final_dict, fp) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a605c755",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c925094",
   "metadata": {},
   "source": [
    "# Forward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d33a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.svm import LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d2d7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVR(random_state=0, tol=1e-05, max_iter=2000)\n",
    "\n",
    "for k in range(50, 550, 50):\n",
    "    # Using Forward Elimination\n",
    "    sfs = SFS(model, \n",
    "             n_features_to_select = k,\n",
    "             direction = 'forward',\n",
    "             scoring = 'accuracy',\n",
    "             n_jobs = -1,\n",
    "             cv=5)\n",
    "\n",
    "    sfs = sfs.fit(X, y)\n",
    "    selected_feat_fw = X.columns[(sfs.support_)]\n",
    "    # save the info\n",
    "    fw_final_dict = {\n",
    "        \"k\": k,\n",
    "        \"columns\": selected_feat_fw.tolist(),\n",
    "        \"importances\": None,\n",
    "    }\n",
    "\n",
    "    with open(fs_fm_path + \"forward-elimination_\" + str(k) + \".json\", \"w\") as fp:\n",
    "        json.dump(fw_final_dict, fp) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78424e39",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d4723a",
   "metadata": {},
   "source": [
    "# Filter Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda27e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, f_regression, mutual_info_regression, r_regression\n",
    "\n",
    "score_funcs = {\n",
    "    'f-classif': f_classif,\n",
    "    'chi2': chi2,\n",
    "    'f-regression': f_regression,\n",
    "    'mutual-info-regression': mutual_info_regression,\n",
    "    'r-regression': r_regression,\n",
    "}\n",
    "\n",
    "for name, func in score_funcs.items():\n",
    "    for k in range(50, 550, 50):\n",
    "        selector = SelectKBest(func, k=k)\n",
    "        selector.fit(X, y)\n",
    "        columns = selector.get_feature_names_out().tolist()\n",
    "\n",
    "        l = list(zip(scores, columns))\n",
    "        l.sort(reverse=True)\n",
    "\n",
    "        scores, columns = zip(*l)\n",
    "\n",
    "        final_dict = {\n",
    "            \"k\": k,\n",
    "            \"columns\": columns,\n",
    "        }\n",
    "\n",
    "        with open(fs_fm_path + name + \"_\" + str(k) + \".json\", \"w\") as fp:\n",
    "            json.dump(final_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8236c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold()\n",
    "selector.fit(X)\n",
    "scores = selector.variances_\n",
    "columns = X.columns\n",
    "\n",
    "l = list(zip(scores, columns))\n",
    "l.sort(reverse=True)\n",
    "\n",
    "scores, columns = zip(*l)\n",
    "\n",
    "for k in range(50, 550, 50):\n",
    "\n",
    "    final_dict = {\n",
    "        \"k\": k,\n",
    "        \"columns\": columns[:k],\n",
    "        \"importances\": scores[:k],\n",
    "    }\n",
    "\n",
    "    with open(fs_fm_path + \"variance-threshold_\" + str(k) + \".json\", \"w\") as fp:\n",
    "        json.dump(final_dict, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
