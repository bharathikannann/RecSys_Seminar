---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.13.8
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
from sklearn import metrics
from sklearn.ensemble import RandomForestRegressor
import pandas as pd
from configparser import ConfigParser
import json
import os
from os.path import exists
import pickle
import numpy as np
from collections import OrderedDict

from myfm import MyFMRegressor
```

```{python}
#Read config.ini file
config = ConfigParser()
config.read("config.ini")
dataset_info = config["DATASETS"]
fm_data_path = dataset_info['fm_path']
rf_data_path = dataset_info['rf_path']
train_set_filename = dataset_info['train_filename']
test_set_filename = dataset_info['test_filename']
description_filename = dataset_info['description_filename']

model_info = config["MODELS"]
model_path = model_info['model_path']
fm_filename = model_info['fm_model_filename']
rf_filename = model_info['rf_model_filename']

fs_info = config['FEATURE_SELECTION']
fs_path = fs_info['fs_rf_path']
```

### FM Training and Testing

```{python}
train = pickle.load(open(fm_data_path + train_set_filename, 'rb'))
test = pickle.load(open(fm_data_path + test_set_filename, 'rb'))
X_train = train.drop(['rating'], axis=1)
X_test = test.drop(['rating'], axis=1)
y_train = train['rating']
y_test = test['rating']


with open(fm_data_path + description_filename) as f:
    meta_data = json.load(f)
    group_shapes = [v for k,v in meta_data.items()]
```

---


# Random Forest column names to MyFM columns

```{python}
# Getting all the methods we have implemeted, file name represents the method name we have immplemented
available_methods_rf = []
for subdir, dirs, files in os.walk(fs_path):
    for file in files:
        available_methods_rf.append(file[:-5])
pd.DataFrame(available_methods_rf)
```

```{python}
# Combining all the data we have in our feature selection folder for randomforest
# Folder names represent the feature seletion method, so creating a key for all methods
selected_col_dict_rf = {}
for i in available_methods_rf:
    selected_col_dict_rf[i] = []
selected_col_dict_rf.keys()
```

```{python}
# Storing corresponding json data in the key.
for i in range(len(available_methods_rf)):
    f = open(fs_path + available_methods_rf[i] + ".json")
    selected_col_dict_rf[available_methods_rf[i]] = json.load(f)
```

```{python}
path = dataset_info['ori_path']
genre_cols = pd.read_csv(path + 'ml-100k/u.genre', sep='|', header=None)[0].to_numpy().tolist()
```

# Convert the columns obtained from rf dataset methods to fm dataset

```{python}
def covert_rf_to_fm(x_col_rf, X_train, genre_cols):
    
    '''
    Convert the columns obtained from rf dataset methods to fm dataset
    * x_cols_rf - the selected columns by the  method
    * genre_cols - The total genre list. Used to group them in group shapes.
                   Every genre is a different feaure in random forest. but in MyFM 
                   all the genre should be combined into a single key.
    
    '''
    
    # --------------------------------------------------------
    # Preprocessing columns
    # --------------------------------------------------------
    # Timestamp and release date columns have extra 'fm' character before. 
    # For conversion of rf columns to fm columns, names are changed
    for col in ['timestamp', 'release_date', 'age']:
        if col in x_col_rf:
            x_col_rf.remove(col)
            x_col_rf.append('fm_' + col)

    # Adding movie_id and user_id columns if not present
    for col in ['movie_id', 'user_id']:
        if col not in x_col_rf:
            x_col_rf.append(col)
    
    # --------------------------------------------------------
    # Creating dataset and metadata
    # --------------------------------------------------------
    meta_data_rf = OrderedDict()
    X_train_rf = pd.DataFrame([])
    
    # Convert only the column's present in the selected method
    for col in x_col_rf:
        # For all normal ohe columns
        if col in ['movie_id','user_id','fm_timestamp','fm_release_date','zip_code','fm_age','occupation','last_watched','sex','age']:
            # Filter method filters columns which contains the regex argument
            temp = X_train.filter(regex=col, axis=1)
            X_train_rf = pd.concat([X_train_rf, temp], axis = 1)
            meta_data_rf[col] = temp.shape[1]
    
    # Processing mean and cummulative mean rating
    # --------------------------------------------------------
    # For mean rating, it has the same characters with cum_mean_rate and has no unique words
    # So these columns are processed separately. It is done at last to not make any confusion :)
    # if both are present
    if 'mean_rate' and 'cum_mean_rate' in x_col_rf:
        # a is union, has both mean and cum_mean_rate because of regex
        # b has only cum_mean_rating
        a = X_train.filter(regex='mean_rate', axis=1)
        b = X_train.filter(regex='cum_mean_rate', axis=1)
        # Taking intersection with a and b gives cum_mean_rate and its negation will give mean_rate
        # cum_mean_rating will be NAN and droppped
        a = a[~a.isin(b)].dropna(axis=1)
        X_train_rf = pd.concat([X_train_rf, a], axis = 1)
        X_train_rf = pd.concat([X_train_rf, b], axis = 1)
        meta_data_rf['mean_rate'] = a.shape[1]
        meta_data_rf['cum_mean_rate'] = b.shape[1]
        
    # If atleast 1 is present, There will be no clash so processed normally
    else:
        for col in x_col_rf:
            if col in ['mean_rate','cum_mean_rate']:
                temp = X_train.filter(regex=col, axis=1)
                X_train_rf = pd.concat([X_train_rf, temp], axis = 1)
                meta_data_rf[col] = temp.shape[1]
    
    # Processing genre
    # --------------------------------------------------------
    # Genre is combined into a single key in group shapes
    # If there are any genre columns in x_col_rf
    if list(set(genre_cols) & set(x_col_rf)):
        meta_data_rf['genre'] = 0
        # For all the genre in x_col_rf
        for col in list(set(genre_cols) & set(x_col_rf)):
            temp = X_train.filter(regex=col, axis=1)
            X_train_rf = pd.concat([X_train_rf, temp], axis = 1)
            meta_data_rf['genre'] = meta_data_rf['genre'] + 1 
            
    return X_train_rf, meta_data_rf
```

# Select from Model Dataset


### Choosing the method for current evaluation

> **Important - Need to change the name of the selected columns (sel_from_model_col_rf) for everymethod and also chosse the corresponding method id**

```{python}
sel_from_model_col_rf
```

```{python}
# The index in the available methods list represents the model we are choosing now
# 3 - select-from-model method
choose_method = 5

# get features for the method
sel_from_model_col_rf = selected_col_dict_rf[available_methods_rf[choose_method]]["columns"]

# convert the dateset
X_train_sel_from_model, meta_data_sel_from_model = covert_rf_to_fm(sel_from_model_col_rf, X_train, genre_cols)
X_test_sel_from_model, meta_data_sel_from_model = covert_rf_to_fm(sel_from_model_col_rf, test.drop(['rating'], axis=1), genre_cols)

# Convert metadata to list
meta_data_sel_from_model_list = [j for i,j in meta_data_sel_from_model.items()]

meta_data_sel_from_model
```

```{python}
fm = MyFMRegressor(rank=10)
fm.fit(X_train_sel_from_model, y_train, n_iter=200, group_shapes=meta_data_sel_from_model_list, n_kept_samples=200)

prediction = fm.predict(X_test_sel_from_model)
rmse = ((y_test - prediction) ** 2).mean() ** .5
mae = np.abs(y_test - prediction).mean()
print(f'rmse={rmse}, mae={mae}')
```

# Random forest Dataset
- Top N features are picked. N - hyperparameter 

```{python}
choose_method = 6

# No of top N features to get
get_top_N_fetaures = 15

# get features for the method
random_forest_col_rf = selected_col_dict_rf[available_methods_rf[choose_method]]["columns"]

# convert the dataset
X_train_random_forest, meta_data_random_forest = covert_rf_to_fm(random_forest_col_rf[:get_top_N_fetaures], X_train, genre_cols)
X_test_random_forest, meta_data_random_forest = covert_rf_to_fm(random_forest_col_rf[:get_top_N_fetaures], test.drop(['rating'], axis=1), genre_cols)

# Convert metadata to list
meta_data_random_forest_list = [j for i,j in meta_data_random_forest.items()]

meta_data_random_forest
```

## 1. Random Forest

```{python}
fm = MyFMRegressor(rank=10)
fm.fit(X_train_random_forest, y_train, n_iter=200, group_shapes=meta_data_random_forest_list, n_kept_samples=200)

prediction = fm.predict(X_test_random_forest)
rmse = ((y_test - prediction) ** 2).mean() ** .5
mae = np.abs(y_test - prediction).mean()
print(f'rmse={rmse}, mae={mae}')
```

---


# My FM Models for each Feature Selection Method


# Baseline

```{python}
fm = MyFMRegressor(rank=10)
fm.fit(X_train, y_train, n_iter=200, group_shapes=group_shapes, n_kept_samples=200)
```

```{python}
prediction = fm.predict(X_test)
rmse = ((y_test - prediction) ** 2).mean() ** .5
mae = np.abs(y_test - prediction).mean()
print(f'rmse={rmse}, mae={mae}')
```

## Select from Model Extra

```{python}
fm = MyFMRegressor(rank=10)
fm.fit(X_train_sel_from_model, y_train, n_iter=200, group_shapes=meta_data_sel_from_model_list, n_kept_samples=200)
```

```{python}
prediction = fm.predict(X_test_sel_from_model)
rmse = ((y_test - prediction) ** 2).mean() ** .5
mae = np.abs(y_test - prediction).mean()
print(f'rmse={rmse}, mae={mae}')
```

---


# Random Experiments

Just randomly selecting some columns based on some analysis and seeing how the performance improves

```{python}
import ipywidgets as widgets
w = widgets.SelectMultiple(
    options=['movie_id','user_id', 'timestamp', 'release_date', 'zip_code', 'age', 'occupation', 'sex',
       'last_watched', 'mean_rate', 'cum_mean_rate', 'unknown', 'Action',
       'Adventure', 'Animation', "Children's" ,'Comedy', 'Crime',
       'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical',
       'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'],
    value = ['movie_id','user_id','timestamp', 'release_date', 'zip_code', 'age', 'occupation', 'sex',
       'last_watched', 'mean_rate', 'cum_mean_rate'],
    rows=20,
    description='Columns',
    disabled=False
)
w
```

```{python}
random_selections = list(w.value)
random_selections
```

```{python}
# convert the dateset
X_train_random_selection, meta_data_random_selection= covert_rf_to_fm(random_selections, X_train, genre_cols)
X_test_random_selection, meta_data_random_selection= covert_rf_to_fm(random_selections, X_test, genre_cols)

# col_to_drop = 5
# meta_data_random_selection['occupation'] = col_to_drop

# col_to_drop = 5
# meta_data_random_selection['zip_code'] = col_to_drop
# Convert metadata to list
meta_data_random_selection_list = [j for i,j in meta_data_random_selection.items()]

meta_data_random_selection
```

```{python}
# f = open(fs_path + 'random-forest-feature-importance_v2'  + ".json")
# temp = json.load(f)

# import re
# r = re.compile(".*zip_code")
# newlist = list(filter(r.match, temp['columns'])) 
# newlist[5:]

# X_train_random_selection.drop(newlist[col_to_drop:], axis=1, inplace = True)
# X_test_random_selection.drop(newlist[col_to_drop:], axis=1, inplace = True)
```

```{python}
fm = MyFMRegressor(rank=10)
fm.fit(X_train_random_selection, y_train, n_iter=200, group_shapes=meta_data_random_selection_list, n_kept_samples=200)

# # Training data RMSE
# prediction_train = fm.predict(X_train_random_selection)
# rmse_train = ((y_train - prediction_train) ** 2).mean() ** .5
# mae_train = np.abs(y_train - prediction_train).mean()
# print("Training Metrics")
# print(f'rmse={rmse_train}, mae={mae_train}')

# Test data RMSE
prediction = fm.predict(X_test_random_selection)
rmse = ((y_test - prediction) ** 2).mean() ** .5
mae = np.abs(y_test - prediction).mean()
print("Test Metrics")
print(f'rmse={rmse}, mae={mae}')
```

```{python}
random_selections_info = {}
random_selections_info["Columns"] = ', '.join(random_selections)
random_selections_info['rmse_train'] = str(rmse_train)
random_selections_info['mse_train'] = str(mae_train)
random_selections_info['rmse_test'] = str(rmse)
random_selections_info['mse_test'] = str(mae)
random_selections_info['Additional Info'] = ""

import json
with open("rmse_infos/" + str(round(rmse,6))+".json", "w") as outfile:
    json.dump(random_selections_info, outfile)
```

# Random Forest Model for MYFM data

```{python}
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
```

```{python}
# initialize and fit the model
forest = RandomForestClassifier(n_estimators=100)
forest.fit(X_train_random_selection, y_train)
```

```{python}
from sklearn.metrics import accuracy_score, confusion_matrix
y_pred = forest.predict(X_test_random_selection)
accuracy_score(y_test, y_pred) * 100
# confusion_matrix(y_test, y_pred)
```

```{python}
print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))
```

```{python}
# pickle.dump(forest, open('rmse_infos/randomforestforfmdata', 'wb'))
```

```{python}
# list of column names
feature_names = list(X_train_random_selection.columns)

# extract the feature importance values
std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)
rf_feature_importances = pd.DataFrame(
    {"feature": feature_names, "importance": forest.feature_importances_}
)

rf_feature_importances.sort_values("importance", ascending=False,inplace=True)
```

```{python}
rf_feature_importances
```

```{python}
import matplotlib.pyplot as plt
# Visualization is nice to have, but not necessary
# visualize the importance of each feature
fig, ax = plt.subplots(figsize=(12,6))
# ax.set_ylim([0, 30])
rf_feature_importances.plot.bar(x='feature', y='importance', ax=ax, legend=False, stacked = True)
ax.set_title("Feature importances")
ax.set_ylabel("Importance in %")
fig.tight_layout()
```

# Default program given my MyFM

```{python}
# import numpy as np
# from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder
# from sklearn import metrics

# import myfm
# from myfm.utils.benchmark_data import MovieLens100kDataManager

# FM_RANK = 10

# data_manager = MovieLens100kDataManager()
# df_train, df_test = data_manager.load_rating_predefined_split(fold=3)

# FEATURE_COLUMNS = ['user_id', 'movie_id']
# ohe = OneHotEncoder(handle_unknown='ignore')

# X_train = ohe.fit_transform(df_train[FEATURE_COLUMNS])
# X_test = ohe.transform(df_test[FEATURE_COLUMNS])
# y_train = df_train.rating.values
# y_test = df_test.rating.values

# fm = myfm.MyFMRegressor(rank=FM_RANK, random_seed=42)
# fm.fit(X_train, y_train, n_iter=200, n_kept_samples=200)

# prediction = fm.predict(X_test)
# rmse = ((y_test - prediction) ** 2).mean() ** .5
# mae = np.abs(y_test - prediction).mean()
# print(f'rmse={rmse}, mae={mae}')
```

---

```{python}
# callback = MyRegressionCallback(5, X_test, y_test.values)

# create parent folder if doesn't exist
os.makedirs(model_path, exist_ok=True)

# load from pickle dump, if it exists. Otherwise train model and then save/'pickle' it
fm_model_path = model_path + fm_filename
if exists(fm_model_path):
    fm = pickle.load(open(fm_model_path, 'rb'))
else:
    fm = MyFMRegressor(rank=1).fit(X_train, y_train, n_iter=300, group_shapes=group_shapes)
    pickle.dump(fm, open(fm_model_path, 'wb'))

fm_error = metrics.mean_squared_error(y_test, fm.predict(X_test), squared=False)
print(f'FM Regression error: {fm_error}')
```

### RF Training and Testing

```{python}
train = pickle.load(open(rf_data_path + train_set_filename, 'rb'))
test = pickle.load(open(rf_data_path + test_set_filename, 'rb'))
# train = pd.read_csv(rf_data_path + train_set_filename, sep=',', encoding='latin-1', index_col=None, nrows=1000)
# test = pd.read_csv(rf_data_path + test_set_filename, sep=',', encoding='latin-1', index_col=None, nrows=1000)
X_train = train.drop(['rating'], axis=1)
X_test = test.drop(['rating'], axis=1)
y_train = train['rating']
y_test = test['rating']
```

```{python}
rf_model_path = model_path + rf_filename
if exists(rf_model_path):
    rf = pickle.load(open(rf_model_path, 'rb'))
else:
    rf = RandomForestRegressor(n_estimators = 100, random_state = 42).fit(X_train, y_train)
    pickle.dump(rf, open(rf_model_path, 'wb'))

rf_error = metrics.mean_squared_error(y_test, rf.predict(X_test), squared=False)
print(f'Random Forest error: {rf_error}')

```

### RF Feature Importance

```{python}
import matplotlib.pyplot as plt

# list of column names
feature_names = list(X_train.columns)

# extract the feature importance values
std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)
rf_feature_importances = pd.DataFrame(
    {"feature": feature_names, "importance": rf.feature_importances_}
)

rf_feature_importances.sort_values("importance", ascending=False,inplace=True)

# visualize the importance of each feature
fig, ax = plt.subplots(figsize=(12,6))
rf_feature_importances.plot.bar(x='feature', y='importance', yerr=std, ax=ax, legend=False)
ax.set_title("Feature importances")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
```
