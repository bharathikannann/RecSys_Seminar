---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.13.8
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

```{python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import calendar
import datetime
import json 
import os  
import pickle
from configparser import ConfigParser
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
```

### General helper functions

```{python}
# format release date
def format_release_date(data):
    arr = list()
    for i,l in enumerate(data):
        if ord(l) == 45:
            arr.append(i)
    date = int(data[0:arr[0]])
    month_name = data[arr[0]+1:arr[1]]
    datetime_object = datetime.datetime.strptime(month_name, "%b")
    month = datetime_object.month
    year = int(data[arr[1]+1:arr[1]+5])
    date = datetime.datetime(year, month, date)
    utc_time = calendar.timegm(date.utctimetuple())
    return utc_time 

# format timestamp
def date_only_from_datetime(data):
    temp = datetime.datetime.fromtimestamp(data)
    date = datetime.datetime(temp.year, temp.month, temp.day) # temp.hour
    return date

# get mean rating for the user x
def get_mean_rating(x, mean_rating):
    return float(mean_rating[mean_rating['user_id'] == x]['mean_rating'].to_numpy()[0])
```

```{python}
#Read config.ini file
config = ConfigParser()
config.read("config.ini")
fileinfo = config["DATASETS"]

path = fileinfo['ori_path']
fm_export_path = fileinfo['fm_path']
rf_export_path = fileinfo['rf_path']
train_set_filename = fileinfo['train_filename']
test_set_filename = fileinfo['test_filename']
description_filename = fileinfo['description_filename']

# import user, data, item and genre data
u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']
users = pd.read_csv(path + 'ml-100k/u.user', sep='|', names=u_cols, encoding='latin-1', parse_dates=True, header=None) 
d_cols = ['user_id', 'movie_id', 'rating', 'timestamp']
data = pd.read_csv(path + 'ml-100k/u.data', sep='\t', names=d_cols, encoding='latin-1', header=None)
genre_cols = pd.read_csv(path + 'ml-100k/u.genre', sep='|', header=None)[0].to_numpy().tolist()
m_cols = ['movie_id', 'movie_title', 'release_date', 'video_release_date','imdb_url']
m_cols.extend(genre_cols)
movies = pd.read_csv(path + 'ml-100k/u.item', sep='|', names=m_cols, usecols=range(24), encoding='latin-1', header=None)

# merge user, data and item
movie_ratings = pd.merge(movies, data)
df = pd.merge(movie_ratings, users)
```

### General preprocessing that applies to both FM and RF

```{python}
# dropping some rows that has no release date 
df.drop(index = df[df['release_date'].isnull() == True].index, inplace = True)
df.reset_index(drop=True, inplace=True)

# format release_date to unix timestamp
df['release_date'] = df['release_date'].apply(lambda x: format_release_date(x))

# convert to binary
df['sex'] = (df['sex'] == 'M').astype(int)

# take first character only
df['zip_code'] = df['zip_code'].str[0]
```

```{python}
# RF forest data needs to be preprocessed differently. 
# Therefore need to save copy of df first
rf_df = df.copy(deep=True)
```

### Preprocessing specific for FM

```{python}
# format age
age_labels = []
age_bins = np.arange(0,90,10)
for i in range(len(age_bins)-1):
    age_labels.append(str(age_bins[i]) + '-' + str(age_bins[i+1]))
# convert ages to group of age ranges
df['age'] = pd.cut(df['age'], bins = age_bins, labels=age_labels)
```

```{python}
# preprocess timestamp and release date
# only use year, month and day from the datetime
df['timestamp'] = df['timestamp'].apply(lambda x : date_only_from_datetime(x))
df['release_date'] = df['release_date'].apply(lambda x : date_only_from_datetime(x))
```

```{python}
# Start to set up df_final and col_len
col_len = {}
# initialize with the correct shape of 0 x 99991
df_final = pd.DataFrame(columns = [], index = range(len(df)))
```

```{python}
# columns that need ohe
ohe_columns = ["movie_id", "user_id", "timestamp", "release_date", "zip_code", "age", "occupation"]
for col in ohe_columns:
    df_dummies = pd.get_dummies(df[col], prefix=col)
    col_len[col] = len(df_dummies.columns)
    df_final = pd.concat([df_final, df_dummies], axis = 1)

# special case: genre (already ohe in original dataset)
col_len["genre"] = len(genre_cols)
df_final = pd.concat([df_final, df[genre_cols]], axis = 1)

# columns that don't need ohe
non_ohe_columns = ["sex"]
for col in non_ohe_columns:
    col_len[col] = 1
df_final = pd.concat([df_final, df[non_ohe_columns]], axis = 1)

# rating column (no need to add to col_len)
df_final = pd.concat([df_final, df[['rating']]], axis = 1)

print(df_final.shape)
print(col_len)
df_final.head()
```

```{python}
# Splitting the data into test and train
X_train, X_test, y_train, y_test = train_test_split(df_final.drop(['rating'], axis = 1), df_final['rating'], random_state=42)

# training and test data is combined to a single dataframe
df_train = pd.concat([X_train,pd.DataFrame(y_train)], axis = 1)
df_test = pd.concat([X_test,pd.DataFrame(y_test)], axis = 1)

```

```{python}
# Saving the FM data
# create parent folder if doesn't exist
os.makedirs(fm_export_path, exist_ok=True)

# export csv file
pickle.dump(df_train, open(fm_export_path + train_set_filename, 'wb'))
pickle.dump(df_test, open(fm_export_path + test_set_filename, 'wb'))
# df_train.to_csv(fm_export_path + 'ml-100k-preprocessed-train.csv', index = False)
# df_test.to_csv(fm_export_path + 'ml-100k-preprocessed-test.csv', index = False)

# saving info about data
with open(fm_export_path + description_filename, "w") as outfile:
    json.dump(col_len, outfile)

# del to free up memory
del(df)
```

### Preprocessing specific for RF

```{python}
# Splitting the data into test and train
X_train, X_test, y_train, y_test = train_test_split(rf_df.drop(['rating'], axis = 1), rf_df['rating'], random_state=42)

# training and test data is combined to a single dataframe
df_train = pd.concat([X_train,pd.DataFrame(y_train)], axis = 1)
df_test = pd.concat([X_test,pd.DataFrame(y_test)], axis = 1)
```

```{python}
# Get mean and cumulative mean
# it is only done for training data, since we should not take statistics about rating from test data
data_train = df_train[['user_id','movie_id','rating','timestamp']]

# calculating cumulative mean rating based on timestamp sorted in ascending order
data_train = data_train.sort_values(['user_id', 'timestamp']).reset_index(drop=True)
data_train['one'] = 1
data_train['cumsum'] = data_train.groupby('user_id')['one'].cumsum()
data_train['cum_mean_rate'] = data_train.groupby('user_id')['rating'].cumsum() / data_train['cumsum']

# calculating mean rating for each user
mean_rating = data_train.groupby('user_id')['rating'].sum() / data_train.groupby('user_id')['one'].sum()
mean_rating = mean_rating.reset_index()
mean_rating.rename(columns = {0:'mean_rating'}, inplace = True)

# getting mean rate for the corresponding user
data_train['mean_rate'] = data_train['user_id']
data_train["mean_rate"] = data_train['mean_rate'].apply(lambda x: get_mean_rating(x, mean_rating))

# merging to the original dataframe
df_train = df_train.merge(data_train, how='left', left_on=['timestamp', 'user_id', 'movie_id', 'rating'], right_on=['timestamp', 'user_id', 'movie_id', 'rating'])

# during testing we won't have the rating value, so we should use the running mean form training data.
df_test['mean_rate'] = df_test['user_id'].apply(lambda x: get_mean_rating(x, mean_rating))
df_test['cum_mean_rate'] = df_test['mean_rate']
```

```{python}
# droping all unnecessary columns
unnecessary_columns_train = ["video_release_date", "imdb_url", "movie_title", "one", "cumsum"]
unnecessary_columns_test = ["video_release_date", "imdb_url", "movie_title"]
df_train.drop(unnecessary_columns_train, axis = 1, inplace = True)
df_test.drop(unnecessary_columns_test, axis = 1, inplace = True)
```

```{python}
# converting objects to integers, since scikit learn supports only numerical values
le = preprocessing.LabelEncoder()

label_encoding_columns = ['occupation','zip_code','sex']
for col in label_encoding_columns:
    df_train[col] = le.fit_transform(df_train[col])
    df_test[col] = le.fit_transform(df_test[col])    
```

```{python}
# create parent folder if doesn't exist
os.makedirs(rf_export_path, exist_ok=True)

# Saving the RF data
pickle.dump(df_train, open(rf_export_path + train_set_filename, 'wb'))
pickle.dump(df_test, open(rf_export_path + test_set_filename, 'wb'))
# df_train.to_csv(rf_export_path + train_set_filename, index = False)
# df_test.to_csv(rf_export_path + test_set_filename, index = False)

```
