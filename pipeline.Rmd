---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.13.8
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
from sklearn import metrics
from sklearn.ensemble import RandomForestRegressor
import pandas as pd
from configparser import ConfigParser
import json
import os
from os.path import exists
import pickle
import numpy as np
from collections import OrderedDict

from myfm import MyFMRegressor
# from myfm.utils.callbacks import RegressionCallback

# class MyRegressionCallback(RegressionCallback):
#     def __call__(self, i, fm, hyper, history):
#         should_stop, description = super(MyRegressionCallback, self).__call__(i, fm, hyper, history)
#         trace_result = self.result_trace[-1]
#         if len(self.result_trace) > 8:
#             for index in range(8):
#                 old_trace_result = self.result_trace[-(index + 1)]
#                 if abs(old_trace_result['rmse'] - trace_result['rmse']) > 0.0001:
#                     return (should_stop, description)
#             return (True, description)
#         return (should_stop, description)
```

```{python}
#Read config.ini file
config = ConfigParser()
config.read("config.ini")
dataset_info = config["DATASETS"]
fm_data_path = dataset_info['fm_path']
rf_data_path = dataset_info['rf_path']
train_set_filename = dataset_info['train_filename']
test_set_filename = dataset_info['test_filename']
description_filename = dataset_info['description_filename']

model_info = config["MODELS"]
model_path = model_info['model_path']
fm_filename = model_info['fm_model_filename']
rf_filename = model_info['rf_model_filename']

fs_info = config['FEATURE_SELECTION']
fs_path = fs_info['fs_rf_path']
```

### FM Training and Testing

```{python}
train = pickle.load(open(fm_data_path + train_set_filename, 'rb'))
test = pickle.load(open(fm_data_path + test_set_filename, 'rb'))
X_train = train.drop(['rating'], axis=1)
X_test = test.drop(['rating'], axis=1)
y_train = train['rating']
y_test = test['rating']


with open(fm_data_path + description_filename) as f:
    meta_data = json.load(f)
    group_shapes = [v for k,v in meta_data.items()]
```

---


# Random Forest column names to MyFM columns

```{python}
# Getting all the methods we have implemeted, file name represents the method name we have immplemented
available_methods_rf = []
for subdir, dirs, files in os.walk(fs_path):
    for file in files:
        available_methods_rf.append(file[:-5])
pd.DataFrame(available_methods_rf)
```

```{python}
# Combining all the data we have in our feature selection folder for randomforest
# Folder names represent the feature seletion method, so creating a key for all methods
selected_col_dict_rf = {}
for i in available_methods_rf:
    selected_col_dict_rf[i] = []
selected_col_dict_rf.keys()
```

```{python}
# Storing corresponding json data in the key.
for i in range(len(available_methods_rf)):
    f = open(fs_path + available_methods_rf[i] + ".json")
    selected_col_dict_rf[available_methods_rf[i]] = json.load(f)
```

```{python}
path = dataset_info['ori_path']
genre_cols = pd.read_csv(path + 'ml-100k/u.genre', sep='|', header=None)[0].to_numpy().tolist()
```

# Convert the columns obtained from rf dataset methods to fm dataset

```{python}
def covert_rf_to_fm(choose_method:int, x_col_rf, X_train, genre_cols):
    
    '''
    Convert the columns obtained from rf dataset methods to fm dataset
    * choose_method - choosen method form the available methods
    * x_cols_rf - the selected columns by the  method
    * genre_cols - The total genre list. Used to group them in group shapes.
                   Every genre is a different feaure in random forest. but in MyFM 
                   all the genre should be combined into a single key.
    
    '''
    
    # --------------------------------------------------------
    # Preprocessing columns
    # --------------------------------------------------------
    # Timestamp and release date columns have extra 'fm' character before. 
    # For conversion of rf columns to fm columns, names are changed
    for col in ['timestamp', 'release_date', 'age']:
        if col in x_col_rf:
            x_col_rf.remove(col)
            x_col_rf.append('fm_' + col)

    # Adding movie_id and user_id columns if not present
    for col in ['movie_id', 'user_id']:
        if col not in x_col_rf:
            x_col_rf.append(col)
    
    # --------------------------------------------------------
    # Creating dataset and metadata
    # --------------------------------------------------------
    meta_data_rf = OrderedDict()
    X_train_rf = pd.DataFrame([])
    
    # Convert only the column's present in the selected method
    for col in x_col_rf:
        # For all normal ohe columns
        if col in ['movie_id','user_id','fm_timestamp','fm_release_date','zip_code','fm_age','occupation','last_watched','sex','age']:
            # Filter method filters columns which contains the regex argument
            temp = X_train.filter(regex=col, axis=1)
            X_train_rf = pd.concat([X_train_rf, temp], axis = 1)
            meta_data_rf[col] = temp.shape[1]
    
    # Processing mean and cummulative mean rating
    # --------------------------------------------------------
    # For mean rating, it has the same characters with cum_mean_rate and has no unique words
    # So these columns are processed separately. It is done at last to not make any confusion :)
    # if both are present
    if 'mean_rate' and 'cum_mean_rate' in x_col_rf:
        # a is union, has both mean and cum_mean_rate because of regex
        # b has only cum_mean_rating
        a = X_train.filter(regex='mean_rate', axis=1)
        b = X_train.filter(regex='cum_mean_rate', axis=1)
        # Taking intersection with a and b gives cum_mean_rate and its negation will give mean_rate
        # cum_mean_rating will be NAN and droppped
        a = a[~a.isin(b)].dropna(axis=1)
        X_train_rf = pd.concat([X_train_rf, a], axis = 1)
        X_train_rf = pd.concat([X_train_rf, b], axis = 1)
        meta_data_rf['mean_rate'] = a.shape[1]
        meta_data_rf['cum_mean_rate'] = b.shape[1]
        
    # If atleast 1 is present, There will be no clash so processed normally
    else:
        for col in x_col_rf:
            if col in ['mean_rate','cum_mean_rate']:
                temp = X_train.filter(regex=col, axis=1)
                X_train_rf = pd.concat([X_train_rf, temp], axis = 1)
                meta_data_rf[col] = temp.shape[1]
    
    # Processing genre
    # --------------------------------------------------------
    # Genre is combined into a single key in group shapes
    # If there are any genre columns in x_col_rf
    if list(set(genre_cols) & set(x_col_rf)):
        meta_data_rf['genre'] = 0
        # For all the genre in x_col_rf
        for col in list(set(genre_cols) & set(x_col_rf)):
            temp = X_train.filter(regex=col, axis=1)
            X_train_rf = pd.concat([X_train_rf, temp], axis = 1)
            meta_data_rf['genre'] = meta_data_rf['genre'] + 1 
            
    return X_train_rf, meta_data_rf
```

# Select from Model Dataset


### Choosing the method for current evaluation

> **Important - Need to change the name of the selected columns (sel_from_model_col_rf) for everymethod and also chosse the corresponding method id**

```{python}
# The index in the available methods list represents the model we are choosing now
# 3 - select-from-model method
choose_method = 3

# get features for the method
sel_from_model_col_rf = selected_col_dict_rf[available_methods_rf[choose_method]]["columns"]

# convert the dateset
X_train_sel_from_model, meta_data_sel_from_model = covert_rf_to_fm(choose_method, sel_from_model_col_rf, X_train, genre_cols)
meta_data_sel_from_model
```

# Random forest Dataset
- Top N features are picked. N - hyperparameter 

```{python}
choose_method = 2

# No of top N features to get
get_top_N_fetaures = 10

# get features for the method
random_forest_col_rf = selected_col_dict_rf[available_methods_rf[choose_method]]["columns"]

# convert the dateset
X_train_random_forest, meta_data_random_forest = covert_rf_to_fm(choose_method, random_forest_col_rf[:get_top_N_fetaures], X_train, genre_cols)
meta_data_random_forest
```

---

```{python}
# callback = MyRegressionCallback(5, X_test, y_test.values)

# create parent folder if doesn't exist
os.makedirs(model_path, exist_ok=True)

# load from pickle dump, if it exists. Otherwise train model and then save/'pickle' it
fm_model_path = model_path + fm_filename
if exists(fm_model_path):
    fm = pickle.load(open(fm_model_path, 'rb'))
else:
    fm = MyFMRegressor(rank=1).fit(X_train, y_train, n_iter=300, group_shapes=group_shapes)
    pickle.dump(fm, open(fm_model_path, 'wb'))

fm_error = metrics.mean_squared_error(y_test, fm.predict(X_test), squared=False)
print(f'FM Regression error: {fm_error}')

```

### RF Training and Testing

```{python}
train = pickle.load(open(rf_data_path + train_set_filename, 'rb'))
test = pickle.load(open(rf_data_path + test_set_filename, 'rb'))
# train = pd.read_csv(rf_data_path + train_set_filename, sep=',', encoding='latin-1', index_col=None, nrows=1000)
# test = pd.read_csv(rf_data_path + test_set_filename, sep=',', encoding='latin-1', index_col=None, nrows=1000)
X_train = train.drop(['rating'], axis=1)
X_test = test.drop(['rating'], axis=1)
y_train = train['rating']
y_test = test['rating']
```

```{python}
rf_model_path = model_path + rf_filename
if exists(rf_model_path):
    rf = pickle.load(open(rf_model_path, 'rb'))
else:
    rf = RandomForestRegressor(n_estimators = 100, random_state = 42).fit(X_train, y_train)
    pickle.dump(rf, open(rf_model_path, 'wb'))

rf_error = metrics.mean_squared_error(y_test, rf.predict(X_test), squared=False)
print(f'Random Forest error: {rf_error}')

```

### RF Feature Importance

```{python}
import matplotlib.pyplot as plt

# list of column names
feature_names = list(X_train.columns)

# extract the feature importance values
std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)
rf_feature_importances = pd.DataFrame(
    {"feature": feature_names, "importance": rf.feature_importances_}
)

rf_feature_importances.sort_values("importance", ascending=False,inplace=True)

# visualize the importance of each feature
fig, ax = plt.subplots(figsize=(12,6))
rf_feature_importances.plot.bar(x='feature', y='importance', yerr=std, ax=ax, legend=False)
ax.set_title("Feature importances")
ax.set_ylabel("Mean decrease in impurity")
fig.tight_layout()
```
